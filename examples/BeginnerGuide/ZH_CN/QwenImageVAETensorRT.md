# Qwen Image VAE TensorRT 加速优化指南

为了显著提升 Qwen Image 模型在不同场景下的推理速度，我们在 VAE 的 Encoder 和 Decoder 部分均引入了 TensorRT 优化。

针对文本生成图像 (T2I) 与图像生成图像/视频 (I2I) 等任务在输入 Shape 上的不同特点，我们设计了两种维度的加速策略：**静态 Shape 优化 (Static Shape)** 与 **动态 Shape 优化 (Multi-Profile)**。

---

## 1. T2I 场景：静态 Shape (Static Shape) 方案

在 T2I 任务中，生成的图像分辨率通常是固定的（如 16:9, 1:1, 4:3 等）。我们可以明确提前知道推理所用 Shape。因此，采用 **静态分辨率引擎 (Static Shape)** 是性能最佳的选择，因为它可以在底层完全消除动态 Shape 推导带来的开销。

### 1.1 核心优势与性能
*   **极致性能**: VAE 组件独立测试中，Encoder 与 Decoder 平均可达 **~2.0x** 加速；端到端服务模式下 VAE Decoder 平均 **~1.8x** 加速。
*   **按需加载 (Lazy Load)**: 引擎按分辨率按需加载，仅在当前分辨率首次请求时加载对应引擎对（~5GB 显存），切换分辨率时自动释放旧引擎、加载新引擎。相比全量加载（~25GB），大幅降低显存占用，兼容端到端推理场景。

#### VAE 独立测试性能 (H100, 纯 VAE 推理)

| 分辨率 | 尺寸 (WxH) | PT Enc (ms) | TRT Enc (ms) | Enc 加速 | PT Dec (ms) | TRT Dec (ms) | Dec 加速 |
| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |
| **16:9** | 1664x928 | 66.53 | **32.70** | **2.03x** | 103.65 | **49.66** | **2.09x** |
| **9:16** | 928x1664 | 65.72 | **32.22** | **2.04x** | 103.02 | **50.71** | **2.03x** |
| **1:1** | 1328x1328 | 78.16 | **41.95** | **1.86x** | 121.91 | **61.52** | **1.98x** |
| **4:3** | 1472x1140 | 73.99 | **37.23** | **1.99x** | 114.45 | **54.75** | **2.09x** |
| **3:4** | 768x1024 | 31.74 | **17.33** | **1.83x** | 50.77 | **26.86** | **1.89x** |

> 综合平均加速比：Encoder ~1.95x, Decoder ~2.02x

#### 端到端服务模式性能 (H100, Qwen-Image-2512, 5 step, VAE Decoder)

> 注意：T2I 任务不涉及 VAE Encoder（无输入图像），故仅统计 VAE Decoder。

| 分辨率 | 尺寸 (WxH) | PT Dec (ms) | TRT Dec (ms) | Dec 加速 | 首次加载 (ms) |
| :---: | :---: | :---: | :---: | :---: | :---: |
| **16:9** | 1664x928 | 189.3 | **88.4** | **2.14x** | 343.9 |
| **9:16** | 928x1664 | 179.6 | **85.6** | **2.10x** | 226.4 |
| **1:1** | 1328x1328 | 157.6 | **106.2** | **1.48x** | 304.1 |
| **4:3** | 1472x1140 | 148.7 | **94.7** | **1.57x** | 238.0 |
| **3:4** | 768x1024 | 70.4 | **46.1** | **1.53x** | 178.2 |

> 综合平均 Decoder 加速比：~1.8x。「首次加载」列为 Lazy Load 切换分辨率时的一次性开销（含引擎反序列化），后续同分辨率请求不再产生。

#### 两组数据差异说明

端到端绝对耗时高于独立测试，主要原因：
1. **后处理开销**：端到端 `decode()` 包含 `image_processor.postprocess()`（tensor → PIL 图片转换），独立测试返回 tensor 无此开销。
2. **GPU 资源争抢**：端到端场景 Transformer (~30GB) + Text Encoder (~15GB) 常驻显存，L2 Cache 被大模型权重覆盖，VAE 推理时需重新从 HBM 读取，增加了显存访问延迟。
3. **显存碎片化**：PyTorch 动态分配器与 TRT 固定 context 交替使用，PyTorch 侧受碎片影响更大（故其绝对差距更显著）。

### 1.2 预置配置说明
*   **引擎默认存储目录**：`path/to/vae_trt_t2i_static`
*   **目录结构要求**：
    引擎根目录下必须按照以下特定的子目录名称存放分辨率对应的 `.trt` 权重文件（底层代码加载逻辑硬依赖了这些预设的目录名称进行 Lazy Load 查找）：

    ```text
    vae_trt_t2i_static/
    ├── 16_9/        # 对应尺寸 1664x928 (宽x高)
    │   ├── vae_encoder.trt
    │   └── vae_decoder.trt
    ├── 9_16/        # 对应尺寸 928x1664
    │   ├── vae_encoder.trt
    │   └── vae_decoder.trt
    ├── 1_1/         # 对应尺寸 1328x1328
    │   ├── vae_encoder.trt
    │   └── vae_decoder.trt
    ├── 4_3/         # 对应尺寸 1472x1140
    │   ├── vae_encoder.trt
    │   └── vae_decoder.trt
    └── 3_4/         # 对应尺寸 768x1024
        ├── vae_encoder.trt
        └── vae_decoder.trt
    ```

### 1.3 配置使用方法
在对应的 JSON 配置文件中，设置 `vae_type` 为 `tensorrt`，并配置对应存放各特定分辨率目录的根目录，且关闭 `multi_profile` 模式：

```json
{
    "task": "t2i",
    "vae_type": "tensorrt",
    "trt_vae_config": {
        "trt_engine_path": "path/to/vae_trt_t2i_static",
        "multi_profile": false
    }
}
```

---

## 2. I2I 场景：动态 Shape (Multi-Profile) 方案

对于 I2I 等任务而言，用户的输入图像通常是任意尺寸、不受控的，因此 VAE 必须能够受理动态范围的 Shape 输入，不能采用纯静态的引擎。
为兼顾速度与灵活性，我们采用了 **Multi-Profile 动态配置引擎**。构建时在同一个引擎文件中囊括多个优化的档位（Opt Shapes）。

### 2.1 核心优势与性能
*   **优秀的性能提升**: VAE 独立测试中 Encoder 和 Decoder 平均可达 **约 1.45x** 加速；端到端服务模式下 VAE Encoder 平均 **~1.66x** 加速，Decoder 平均 **~1.08x** 加速。
*   **动态最优化适配**: 推理时在底层根据当前传入的图像尺寸，实时查找到距离最近的优化档位，以期获得最优显存排布与算子执行计划。

#### VAE 独立测试性能 (H100, 纯 VAE 推理, 10 轮平均)

**Encoder**:

| 分辨率 | 尺寸 (WxH) | PT Enc (ms) | TRT Enc (ms) | Enc 加速 |
| :---: | :---: | :---: | :---: | :---: |
| **512x512** | 512x512 | 11.00 | **8.53** | **1.29x** |
| **1024x1024** | 1024x1024 | 42.85 | **27.56** | **1.55x** |
| **480p 16:9** | 848x480 | 17.25 | **12.00** | **1.44x** |
| **720p 16:9** | 1280x720 | 38.00 | **25.35** | **1.50x** |
| **768p 4:3** | 1024x768 | 31.98 | **21.76** | **1.47x** |

> Encoder 平均加速比：~1.45x

**Decoder**:

| 分辨率 | 尺寸 (WxH) | PT Dec (ms) | TRT Dec (ms) | Dec 加速 |
| :---: | :---: | :---: | :---: | :---: |
| **512x512** | 512x512 | 17.60 | **12.78** | **1.38x** |
| **1024x1024** | 1024x1024 | 68.16 | **44.93** | **1.52x** |
| **480p 16:9** | 848x480 | 27.67 | **18.85** | **1.47x** |
| **720p 16:9** | 1280x720 | 60.24 | **40.80** | **1.48x** |
| **768p 4:3** | 1024x768 | 51.14 | **34.92** | **1.46x** |

> Decoder 平均加速比：~1.46x。综合 Encoder + Decoder 平均加速比：~1.45x

#### 端到端服务模式性能 (H100, qwen-image-edit-251130, 4 step)

**VAE Encoder**:

| 分辨率 | 尺寸 (WxH) | PT Enc (ms) | TRT Enc (ms) | Enc 加速 |
| :---: | :---: | :---: | :---: | :---: |
| **512x512** | 512x512 | 48.5 | **28.8** | **1.68x** |
| **1024x1024** | 1024x1024 | 48.2 | **28.4** | **1.70x** |
| **480p 16:9** | 848x480 | 48.7 | **29.6** | **1.64x** |
| **720p 16:9** | 1280x720 | 48.6 | **30.1** | **1.62x** |
| **768p 4:3** | 1024x768 | 49.2 | **29.8** | **1.65x** |

> Encoder 平均加速比：~1.66x

**VAE Decoder**:

| 分辨率 | 尺寸 (WxH) | PT Dec (ms) | TRT Dec (ms) | Dec 加速 |
| :---: | :---: | :---: | :---: | :---: |
| **512x512** | 512x512 | 138.4 | **134.0** | **1.03x** |
| **1024x1024** | 1024x1024 | 152.7 | **133.3** | **1.15x** |
| **480p 16:9** | 848x480 | 140.4 | **134.4** | **1.04x** |
| **720p 16:9** | 1280x720 | 139.0 | **134.2** | **1.04x** |
| **768p 4:3** | 1024x768 | 152.8 | **134.8** | **1.13x** |

> Decoder 平均加速比：~1.08x

#### 两组数据差异说明

**Encoder 端到端加速更好（1.66x > 独立 1.45x）**：
- I2I pipeline 中 `resize_mode: "adaptive"` 会将所有输入图像缩放到统一像素总数（`CONDITION_IMAGE_SIZE: 147456`），因此端到端 Encoder 实际编码的是**固定分辨率**，不受测试图像尺寸影响。该固定分辨率恰好是 TRT Multi-Profile 引擎表现较优的档位。
- GPU 资源争抢对 PyTorch 动态内存分配影响更大，进一步拉开差距。

**Decoder 端到端加速大打折扣（1.08x < 独立 1.46x）**：
- `decode()` 中的 `image_processor.postprocess(output_type="pil")` 会执行 tensor → PIL 图片转换（denormalize → clamp → permute → to(uint8) → ToPILImage），这是 **CPU 密集操作**，耗时约 **80-90ms**，TRT 无法加速。
- 独立测试使用 `return_result_tensor=True` 跳过了此开销，端到端服务模式默认 `return_result_tensor=False`。
- 加一个恒定常数必然稀释加速比：以 1024x1024 为例，独立 PT=68ms / TRT=45ms → 1.52x；加 ~85ms 后 PT=153ms / TRT=130ms → 1.18x，与实测 1.15x 吻合。

> **结论**：端到端 Decoder 加速比低不是 TRT 引擎变慢，而是端到端的 vae decoder 计时范围内包含了 TRT 无法加速的 CPU 后处理操作。若需精确衡量 TRT 内核加速效果，应参考独立测试数据。

### 2.2 预置配置说明
*   **引擎默认存储目录**：`path/to/vae_trt_extended_mp`
*   **内置包含的 Optimization Profile 档位与尺寸**：
    1.  `1_1_512` (512x512)
    2.  `1_1_1024` (1024x1024)
    3.  `16_9_480p` (480x848)
    4.  `16_9_720p` (720x1280)
    5.  `16_9_1080p` (1080x1920)
    6.  `9_16_720p` (1280x720)
    7.  `9_16_1080p` (1920x1080)
    8.  `4_3_768p` (768x1024)
    9.  `3_2_1080p` (1088x1620)

*(最大支持图片的高/宽上限为 1920 像素)*

### 2.3 配置使用方法
由于引擎是一个融合了多个档位的单文件/文件夹（如包含 `vae_encoder_multi_profile.trt`），需要将 `multi_profile` 项配置为 true：

```json
{
    "task": "i2i",
    "vae_type": "tensorrt",
    "trt_vae_config": {
        "trt_engine_path": "path/to/vae_trt_extended_mp",
        "multi_profile": true
    }
}
```

---

## 3. 部署准备

在使用前请确保当前系统和镜像环境已安装了 TensorRT 最新依赖（这通常在我们的自定义镜像中已经完备）：

```bash
pip install tensorrt tensorrt-cu12-bindings tensorrt-cu12-libs
```
