# Video Frame Interpolation (VFI)

## Overview

Video Frame Interpolation (VFI) is a technique that generates intermediate frames between existing frames to increase the frame rate and create smoother video playback. LightX2V integrates the RIFE (Real-Time Intermediate Flow Estimation) model to provide high-quality frame interpolation capabilities.

## What is RIFE?

RIFE is a state-of-the-art video frame interpolation method that uses optical flow estimation to generate intermediate frames. It can effectively:

- Increase video frame rate (e.g., from 16 FPS to 32 FPS)
- Create smooth motion transitions
- Maintain high visual quality with minimal artifacts
- Process videos in real-time

## Installation and Setup

### Download RIFE Model

First, download the RIFE model weights using the provided script:

```bash
python tools/download_rife.py
```

This script will:
- Download RIFEv4.26 model from HuggingFace
- Extract and place the model files in the correct directory
- Clean up temporary files

### Model Location

The RIFE model will be installed to:
```
lightx2v/models/vfi/rife/train_log/flownet.pkl
```

## Usage

### Command Line Interface

You can enable RIFE frame interpolation by adding the `--vfi rife` and `--video_fps` parameters:

```bash
python lightx2v/infer.py \
    --model_cls wan2.1 \
    --task t2v \
    --model_path /path/to/model \
    --config_json /path/to/config.json \
    --prompt "A beautiful sunset over the ocean" \
    --save_video_path ./output.mp4 \
    --vfi rife \
    --video_fps 32
```

### Parameters

- `--vfi rife`: Enable RIFE frame interpolation
- `--video_fps`: Target frame rate for the output video

### Configuration

The VFI model is automatically loaded when specified in the configuration. You can also set it programmatically:

```python
config = {
    "vfi": "rife",
    "fps": 16,        # Source frame rate
    "video_fps": 32,  # Target frame rate
    # ... other config options
}
```

## How It Works

### Frame Interpolation Process

1. **Source Video Generation**: The base model generates video frames at the source FPS
2. **Frame Analysis**: RIFE analyzes adjacent frames to estimate optical flow
3. **Intermediate Frame Generation**: New frames are generated between existing frames
4. **Temporal Smoothing**: The interpolated frames create smooth motion transitions

### Technical Details

- **Input Format**: ComfyUI Image tensors [N, H, W, C] in range [0, 1]
- **Output Format**: Interpolated ComfyUI Image tensors [M, H, W, C] in range [0, 1]
- **Processing**: Automatic padding and resolution handling
- **Memory Optimization**: Efficient GPU memory management

## Examples

### Basic Frame Rate Doubling

```bash
# Generate 16 FPS video and interpolate to 32 FPS
python lightx2v/infer.py \
    --model_cls wan2.1 \
    --task t2v \
    --model_path ./models/wan2.1 \
    --config_json ./configs/wan2.1_t2v.json \
    --prompt "A cat playing in the garden" \
    --vfi rife \
    --video_fps 32
```

### Higher Frame Rate Enhancement

```bash
# Generate 16 FPS video and interpolate to 60 FPS
python lightx2v/infer.py \
    --model_cls wan2.1 \
    --task i2v \
    --model_path ./models/wan2.1 \
    --config_json ./configs/wan2.1_i2v.json \
    --image_path ./input.jpg \
    --prompt "Smooth camera movement" \
    --vfi rife \
    --video_fps 60
```

## Performance Considerations

### Memory Usage

- RIFE processing requires additional GPU memory
- Memory usage scales with video resolution and length
- Consider using lower resolutions for longer videos

### Processing Time

- Frame interpolation adds processing overhead
- Higher target frame rates require more computation
- Processing time is roughly proportional to the number of interpolated frames

### Quality vs Speed Trade-offs

- Higher interpolation ratios may introduce artifacts
- Optimal range: 2x to 4x frame rate increase
- For extreme interpolation (>4x), consider multiple passes

## Best Practices

### Optimal Use Cases

- **Motion-heavy videos**: Benefit most from frame interpolation
- **Camera movements**: Smoother panning and zooming
- **Action sequences**: Reduced motion blur perception
- **Slow-motion effects**: Create fluid slow-motion videos

### Recommended Settings

- **Source FPS**: 16-24 FPS (generated by base model)
- **Target FPS**: 32-60 FPS (2x to 4x increase)
- **Resolution**: Up to 720p for best performance

### Troubleshooting

#### Common Issues

1. **Out of Memory**: Reduce video resolution or target FPS
2. **Artifacts in output**: Lower the interpolation ratio
3. **Slow processing**: Check GPU memory and consider using CPU offloading

#### Solutions

```bash
# For memory issues, use lower resolution
--resolution 480

# For quality issues, use moderate interpolation
--video_fps 24  # instead of 60

# For performance issues, enable offloading
--cpu_offload
```

## Technical Implementation

The RIFE integration in LightX2V includes:

- **RIFEWrapper**: ComfyUI-compatible wrapper for RIFE model
- **Automatic Model Loading**: Seamless integration with the inference pipeline
- **Memory Optimization**: Efficient tensor management and GPU memory usage
- **Quality Preservation**: Maintains original video quality while adding frames

## Future Enhancements

Planned improvements for VFI in LightX2V:

- Support for additional VFI models
- Adaptive interpolation based on motion analysis
- Real-time preview during generation
- Batch processing optimization 